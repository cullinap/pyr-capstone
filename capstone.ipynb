{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sodapy import Socrata\n",
    "import config\n",
    "from IPython.display import display, HTML\n",
    "from useful.eda import basic_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import the data from the api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'nyc311_data.csv' in os.listdir('./data'):\n",
    "    OVERWRITE = False\n",
    "else:\n",
    "    OVERWRITE = True\n",
    "\n",
    "OVERWRITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Socrata(config.url,\n",
    "                 config.api_key,\n",
    "                 username=config.username,\n",
    "                 password=config.password)\n",
    "\n",
    "client.timeout = 300\n",
    "\n",
    "SELECT = ['created_date',\n",
    "          'unique_key',\n",
    "          'complaint_type',\n",
    "          'incident_zip',\n",
    "          'incident_address',\n",
    "          'street_name',\n",
    "          'address_type',\n",
    "          'city',\n",
    "          'resolution_description',\n",
    "          'borough',\n",
    "          'latitude',\n",
    "          'longitude',\n",
    "          'closed_date',\n",
    "          'location_type',\n",
    "          'status']\n",
    "\n",
    "LIMIT_START = 0\n",
    "LIMIT = 100000\n",
    "LIMIT_TOT = 10000000\n",
    "\n",
    "if OVERWRITE == True:\n",
    "    print('fetching data from website...')\n",
    "    data_1 = {'df_'+ str(i): \n",
    "        pd.DataFrame.from_records(client.get(\"erm2-nwe9\",\n",
    "                                             limit=LIMIT, \n",
    "                                             Agency='HPD', \n",
    "                                             offset=x, \n",
    "                                             select=','.join(SELECT))\n",
    "                            ) \n",
    "        for i,x in zip(range(100),[x+LIMIT for x in range(LIMIT_START,LIMIT_TOT) if x % LIMIT == 0])\n",
    "    }\n",
    "    \n",
    "    print('processing data...')\n",
    "    df_1 = data_1['df_0']\n",
    "\n",
    "    for key in data_1.keys():\n",
    "        if key != 'df_0':\n",
    "            df_1 = pd.concat([df_1,data_1[key]],sort=False)\n",
    "    \n",
    "    print('converting to csv...')\n",
    "    df_1.to_csv('./data/nyc311_data.csv')\n",
    "    df = pd.read_csv('./data/nyc311_data.csv',low_memory=False)\n",
    "    #display(HTML(df.head(1).to_html()))\n",
    "    basic_info.data_info(df,None)\n",
    "else:\n",
    "    print('file exists')\n",
    "    print('loading file...')\n",
    "    df = pd.read_csv('./data/nyc311_data.csv',low_memory=False); \n",
    "    #display(HTML(df.head(1).to_html()))\n",
    "    basic_info.data_info(df,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prep the borough data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.listdir('./data/PLUTO_for_WEB/')[0].endswith('.csv') == True:\n",
    "    boroughs = {'df_' + i[:2]: \n",
    "                pd.read_csv(f'./data/PLUTO_for_WEB/{i}',low_memory=False) \n",
    "                for i in [x for x in os.listdir('./data/PLUTO_for_WEB/') if x.endswith('.csv')]\n",
    "            }\n",
    "    print(boroughs['df_QN'].head(2))\n",
    "else:\n",
    "    print('download data first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question #1: Top Complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['complaint_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heating, hot water are probably the same so we can combine them also plumbing is probably pretty close too..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['complaint_type'] = df['complaint_type'].apply(lambda x: 'HEATING' if x == 'HEAT/HOT WATER' else x)\n",
    "df['complaint_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Where are the complaints located?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "latitude,longitude = 40.73, -73.93\n",
    "\n",
    "# create map and display it\n",
    "nyc_map = folium.Map(location=[latitude, longitude], zoom_start=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit=100000\n",
    "\n",
    "df_heat = df[df['complaint_type']=='HEATING']\n",
    "\n",
    "df_complaint = df_heat.iloc[0:limit,:]; df_complaint.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HeatMap(data=df_complaint[['latitude','longitude']].dropna(),radius=8, max_zoom=10).add_to(nyc_map)\n",
    "nyc_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df_bar = df_heat['incident_zip'].value_counts().head(20)\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "sns.barplot(x=df_bar.index,y=df_bar.values,order=df_bar.index,palette='Blues')\n",
    "plt.title('Heat Complaint by Zip')\n",
    "plt.xlabel('zip')\n",
    "plt.ylabel('count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Heat - top 5 Zips\n",
    "\n",
    "11226 - Flatbush, Brooklyn <br/>\n",
    "10467 - East Bronx <br/>\n",
    "10458 - Bronx near Fordham <br/>\n",
    "10468 - Fordham Heights <br/>\n",
    "10453 - Near Yankee stadium <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_str = df_heat['incident_address'].value_counts().head(20)\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "sns.barplot(x=df_str.index,y=df_str.values,order=df_str.index,palette='Blues')\n",
    "plt.title('Noise Complaint by street')\n",
    "plt.xlabel('street')\n",
    "plt.ylabel('count')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "latitude,longitude = 40.73, -73.93\n",
    "\n",
    "# create map and display it\n",
    "bx_map = folium.Map(location=[latitude, longitude], zoom_start=10)\n",
    "\n",
    "df_bx = df_heat[df_heat['borough']=='BRONX']\n",
    "\n",
    "HeatMap(data=df_bx[['latitude','longitude']].dropna(),radius=8, max_zoom=10).add_to(bx_map)\n",
    "bx_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bx_str = df_bx['incident_address'].value_counts().head(20)\n",
    "# test_df = df_noise[['latitude','longitude','incident_address']]\n",
    "\n",
    "# _df = pd.DataFrame(test_df['incident_address'].value_counts()).reset_index()\n",
    "# _df.columns = ['incident_address','count']\n",
    "\n",
    "# pd.merge(_df,test_df,how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_noise['street_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "latitude,longitude = 40.73, -73.93\n",
    "\n",
    "# create map and display it\n",
    "bk_map = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
    "\n",
    "df_bk = df_heat[df_heat['borough']=='BROOKLYN']\n",
    "\n",
    "HeatMap(data=df_bk[['latitude','longitude']].dropna(),radius=8, max_zoom=10).add_to(bk_map)\n",
    "bk_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model complaint types - BX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['Address', \n",
    "     'BldgArea', \n",
    "     'BldgDepth', \n",
    "     'BuiltFAR', \n",
    "     'CommFAR', \n",
    "     'FacilFAR', \n",
    "     'Lot', \n",
    "     'LotArea', \n",
    "     'LotDepth', \n",
    "     'NumBldgs', \n",
    "     'NumFloors', \n",
    "     'OfficeArea', \n",
    "     'ResArea', \n",
    "     'ResidFAR', \n",
    "     'RetailArea', \n",
    "     'YearBuilt', \n",
    "     'YearAlter1', \n",
    "     'ZipCode', \n",
    "     'YCoord', \n",
    "     'XCoord']\n",
    "\n",
    "\n",
    "bx_ = boroughs['df_BX'].loc[:,col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['borough']=='BRONX']['complaint_type'].value_counts().head(5).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.get_dummies(df_bx_['location_type']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_bx = df[df['borough']=='BRONX']\n",
    "complaints = [x for x in df[df['borough']=='BRONX']['complaint_type'].value_counts().head(5).index]\n",
    "\n",
    "#tuple(complain\n",
    "df_bx = df[df['borough']=='BRONX']\n",
    "\n",
    "df_bx_ = df_bx[df_bx['complaint_type'].apply(lambda x: x.endswith(tuple(complaints)))]\n",
    "#df_bx_ = df_bx[df_bx['complaint_type'].apply(lambda x: x.endswith('HEATING'))]\n",
    "#df_bx_ = df_bx[df_bx['complaint_type']=='HEATING']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df_bx_col = df_bx_[['incident_address','complaint_type']].rename(columns={'incident_address':'Address'})\n",
    "df_bx_merged = pd.concat([df_bx_col,\n",
    "                          pd.get_dummies(df_bx_col['complaint_type']),\n",
    "                          #pd.get_dummies(df_bx_['location_type'])\n",
    "                        ],\n",
    "                axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,16))\n",
    "sns.heatmap(df_bx_merged.merge(bx_, on='Address').dropna().corr().round(2),cmap='coolwarm',annot=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_bx_merged.merge(bx_, on='Address').dropna(); data.head()\n",
    "#data = data[data['complaint_type']=='HEATING']\n",
    "data['HEATING'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in data.columns if x.isupper() and x != 'HEATING']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_plot(fpr, tpr, roc_auc):\n",
    "    # method I: plt\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d={i: x for x,i in enumerate(data['complaint_type'].unique())}\n",
    "#data['encoded'] = data['complaint_type'].apply(lambda x: d[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "clf = GaussianNB()\n",
    "skip_col = [x for x in data.columns if x.isupper() and x != 'HEATING']\n",
    "\n",
    "#X,y = normalize(data.loc[:,[x for x in col if x != 'Address' and x != skip_col]]),data['encoded']\n",
    "X,y = normalize(data.loc[:,[x for x in col if x != 'Address' and x != skip_col]]),data['HEATING']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.4,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "per = Perceptron()\n",
    "\n",
    "clf1 = SVC(C=0.1, kernel='linear', gamma=1, class_weight='balanced', probability=True)\n",
    "clf2 = GaussianNB()\n",
    "clf3 = CalibratedClassifierCV(per, method='isotonic')\n",
    "#clf3 = RandomForestClassifier(n_estimators=50, random_state=1, max_features=8, min_samples_leaf=8)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('svc', clf1), \n",
    "                                    ('gnb', clf2),\n",
    "                                    ('per', clf3)],\n",
    "                                    voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_X_train,t_y_train = X_train[:10000],y_train[:10000]\n",
    "t_X_test,t_y_test = X_test[:10000],y_test[:10000]\n",
    "\n",
    "eclf.fit(t_X_train,t_y_train)\n",
    "t_y_pred = eclf.predict(t_X_test)\n",
    "print(classification_report(t_y_test, t_y_pred))\n",
    "\n",
    "probs = eclf.predict_proba(t_X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = roc_curve(t_y_test, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "roc_plot(fpr,tpr,roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eclf.fit(X_train,y_train)\n",
    "# y_pred = eclf.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# probs = eclf.predict_proba(X_test)\n",
    "# preds = probs[:,1]\n",
    "# fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "# roc_plot(fpr,tpr,roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param tune RFC\n",
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_dist = {'max_depth': [3,None],\n",
    "              'max_features': randint(1,9),\n",
    "              'min_samples_leaf': randint(1,9),\n",
    "              'criterion': ['gini','entropy']\n",
    "         }\n",
    "\n",
    "tree = RandomForestClassifier(n_estimators=50)\n",
    "\n",
    "tree_cv = RandomizedSearchCV(tree, param_dist, cv=5)\n",
    "\n",
    "tree_cv.fit(X,y)\n",
    "\n",
    "print('Tuned decision tree parameters: {}'.format(tree_cv.best_params_))\n",
    "print('Best score is: {}'.format(tree_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "X,y = normalize(data.loc[:,[x for x in col if x != 'Address']]),data['encoded']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train,y_train)\n",
    "\n",
    "y_pred = perceptron.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,))\n",
    "mlp.fit(X_train,y_train)\n",
    "\n",
    "y_pred = mlp.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
